import os
import sys
import h5py
import numpy as np
import argparse
import LiCSBAS_monitoring as monitoring_lib


def list_original_folders(path):
    return [
        name for name in os.listdir(path)
        if os.path.isdir(os.path.join(path, name)) and not name.endswith('_update')
    ]


def compute_rms(vals_old, vals_new):
    """Calcula RMS entre dos series ya alineadas por offset."""
    if len(vals_old) == 0 or len(vals_new) == 0:
        return np.inf
    offset = vals_old[0] - vals_new[0]
    vals_new_aligned = vals_new + offset
    return np.sqrt(np.mean((vals_old - vals_new_aligned) ** 2))


def choose_union_index(dates_old, ds_old, dates_new, ds_new, method="last", user_idx=None, rms_threshold=None):
    """
    Decide d√≥nde unir la nueva serie a la vieja.
    - method="last": √∫ltima fecha de old
    - method="manual": √≠ndice elegido por el usuario (-1 √∫ltima, -2 pen√∫ltima, etc.)
    - method="varianza": usa coherencia en el solapamiento, con detecci√≥n de outliers en los bordes
    - rms_threshold: si None, se calcula autom√°ticamente usando 2œÉ de incrementos
    """
    n_old = len(dates_old)

    if method == "manual" and user_idx is not None:
        return user_idx  # ejemplo: -1 √∫ltima, -2 pen√∫ltima

    if method == "varianza":
        # buscar solapamiento de fechas
        overlap = np.intersect1d(dates_old, dates_new)
        if len(overlap) == 0:
            print("‚ö†Ô∏è No hay solapamiento, usando √∫ltima fecha")
            return -1

        idx_old_overlap = np.where(np.isin(dates_old, overlap))[0]
        idx_new_overlap = np.where(np.isin(dates_new, overlap))[0]

        vals_old_overlap = ds_old[idx_old_overlap].astype(np.float64)
        vals_new_overlap = ds_new[idx_new_overlap].astype(np.float64)

        # calcular rms_threshold autom√°ticamente si no se pasa
        if rms_threshold is None:
            incr_old = np.diff(vals_old_overlap, axis=0)
            incr_new = np.diff(vals_new_overlap, axis=0)
            rms_threshold = 2 * max(np.std(incr_old), np.std(incr_new))
            print(f"‚ÑπÔ∏è RMS threshold autom√°tico (2œÉ de incrementos) = {rms_threshold:.3f}")

        # RMS normal en todo el solapamiento
        rms_full = compute_rms(vals_old_overlap, vals_new_overlap)
        print(f"üìä RMS en todo el solapamiento = {rms_full:.3f}")

        if rms_full < rms_threshold:
            # buena coherencia ‚Üí uni√≥n en la primera fecha de solapamiento
            best_idx = idx_old_overlap[0]
            print(f"‚úÖ Uni√≥n en intersecci√≥n (idx {best_idx}, fecha {dates_old[best_idx]})")
            return best_idx

        # probar quitando la √∫ltima fecha del old
        if len(idx_old_overlap) > 1:
            rms_drop_last = compute_rms(vals_old_overlap[:-1], vals_new_overlap[:-1])
            print(f"üìä RMS descartando √∫ltima fecha old = {rms_drop_last:.3f}")
            if rms_drop_last < rms_threshold:
                best_idx = idx_old_overlap[0]
                print(f"‚ö†Ô∏è √öltima fecha old parece outlier, uni√≥n en intersecci√≥n (fecha {dates_old[best_idx]})")
                return best_idx

        # probar quitando pen√∫ltima y √∫ltima
        if len(idx_old_overlap) > 2:
            rms_drop_two = compute_rms(vals_old_overlap[:-2], vals_new_overlap[:-2])
            print(f"üìä RMS descartando √∫ltimas 2 fechas old = {rms_drop_two:.3f}")
            if rms_drop_two < rms_threshold:
                best_idx = idx_old_overlap[0]
                print(f"‚ö†Ô∏è √öltimas 2 fechas old parecen outliers, uni√≥n en intersecci√≥n (fecha {dates_old[best_idx]})")
                return best_idx

        # si nada mejora ‚Üí step real ‚Üí unir en la primera fecha nueva
        print("‚ùå Solapamiento incoherente o step en ambas series, usando √∫ltima fecha old")
        return -1

    # por defecto: √∫ltima fecha
    return -1


def merge_cum_files_continuous_accumulate(file_old, file_new, file_out, method="last", user_idx=None):
    with h5py.File(file_old, 'r') as f_old, h5py.File(file_new, 'r') as f_new:
        dates_old = f_old['imdates'][:]
        dates_new = f_new['imdates'][:]
        dates_new_valid = dates_new[~np.isin(dates_new, dates_old)]
        combined_dates = np.sort(np.concatenate((dates_old, dates_new_valid)))

        print(f"Total unique valid dates: {len(combined_dates)}")

        temporal_dsets = ['bperp', 'cum', 'imdates']

        with h5py.File(file_out, 'w') as f_out:
            # copiar datasets est√°ticos
            for key in f_old.keys():
                if key not in temporal_dsets:
                    ds = f_old[key]
                    if ds.shape == ():
                        f_out.create_dataset(key, data=ds[()], dtype=ds.dtype)
                    else:
                        f_out.create_dataset(key, data=ds[:], dtype=ds.dtype)

            f_out.create_dataset('imdates', data=combined_dates, dtype='int32')

            for key in ['bperp', 'cum']:
                ds_old = f_old[key]
                ds_new = f_new[key]

                spatial_shape = ds_old.shape[1:]
                n_combined = len(combined_dates)
                dset_out = f_out.create_dataset(key, shape=(n_combined, *spatial_shape), dtype=ds_old.dtype)

                n_old = len(dates_old)
                dset_out[:n_old] = ds_old[:]

                idx_new_valid = np.where(np.isin(dates_new, dates_new_valid))[0]
                idx_combined_new = np.searchsorted(combined_dates, dates_new_valid)

                vals_new_valid = ds_new[idx_new_valid].astype(np.float64)

                # elegir punto base de uni√≥n
                union_idx = choose_union_index(dates_old, ds_old, dates_new, ds_new,
                                               method=method, user_idx=user_idx)

                last_old_value = ds_old[union_idx].astype(np.float64)

                # trabajar con incrementos de la nueva
                increments = np.zeros_like(vals_new_valid)
                if len(vals_new_valid) > 0:
                    increments[0] = vals_new_valid[0]
                if len(vals_new_valid) > 1:
                    increments[1:] = vals_new_valid[1:] - vals_new_valid[:-1]

                accumulated = np.cumsum(increments, axis=0) + last_old_value

                for i, idx_c in enumerate(idx_combined_new):
                    dset_out[idx_c] = accumulated[i]

        print("‚úÖ Combined data saved to:", file_out)


def main():
    parser = argparse.ArgumentParser(description="Combine LiCSBAS cum.h5 files for continuous accumulation")
    parser.add_argument("-t", "--tsadir", required=True, help="Time-series analysis directory (e.g., TS_GEOCml1clip)")
    parser.add_argument("--varianza", action="store_true", help="Elegir uni√≥n autom√°ticamente usando coherencia en solapamiento")
    parser.add_argument("--union_idx", type=int, default=None, help="Elegir √≠ndice manual (-1 √∫ltima, -2 pen√∫ltima, etc.)")

    args = parser.parse_args()
    tsadir = args.tsadir

    if not os.path.isdir(tsadir):
        print(f"Error: Directory not found: {tsadir}")
        sys.exit(1)

    print("Monitoring approach enabled")

    ifgdir = tsadir.replace("TS_", "")
    ifgdir = monitoring_lib.update_ifgdir12_16(ifgdir)
    ifgdir = ifgdir.replace("_update", "")
    tsadir = f"TS_{ifgdir}"
    tsadir_update = f"{tsadir}_update"

    oldfile = os.path.join(tsadir, "cum.h5")
    newfile = os.path.join(tsadir_update, "cum.h5")
    updatefile = os.path.join(tsadir, "cum_update.h5")

    if not os.path.exists(oldfile):
        print(f"Old file not found: {oldfile}")
        sys.exit(1)
    if not os.path.exists(newfile):
        print(f"New file not found: {newfile}")
        sys.exit(1)

    # decidir m√©todo
    if args.union_idx is not None:
        method = "manual"
    elif args.varianza:
        method = "varianza"
    else:
        method = "last"

    merge_cum_files_continuous_accumulate(oldfile, newfile, updatefile, method=method, user_idx=args.union_idx)


if __name__ == "__main__":
    main()


'''
Objetivo del script

El script combina dos series de tiempo acumuladas (cum.h5) generadas por LiCSBAS:

Serie antigua: ya procesada y acumulada.

Serie nueva: datos recientes que se quieren unir a la antigua.

El resultado es un archivo combinado (cum_update.h5) donde la acumulaci√≥n es continua y se evita duplicar fechas.

Flujo principal

Preparaci√≥n de directorios y archivos

Toma un directorio de an√°lisis de series de tiempo (TS_...).

Localiza los archivos antiguos (cum.h5) y nuevos (TS_..._update/cum.h5).

Crea el archivo de salida (cum_update.h5).

Elecci√≥n del punto de uni√≥n

Si las series tienen fechas en com√∫n, se analiza el solapamiento para decidir d√≥nde unir:

Manual: el usuario elige el √≠ndice de uni√≥n.

√öltima: se une al final de la serie vieja.

Varianza: se busca coherencia en el solapamiento y se detectan posibles ‚Äústeps‚Äù (cambios bruscos):

Calcula el RMS (ra√≠z del error cuadr√°tico medio) entre los valores antiguos y nuevos en las fechas solapadas.

Compara el RMS con un umbral autom√°tico, calculado como 2œÉ de los incrementos de la serie (diferencias entre fechas consecutivas).

Esto permite distinguir cambios bruscos reales de la variabilidad normal de la serie.

Si el RMS es bajo ‚Üí uni√≥n en la primera fecha de solapamiento.

Si el RMS es alto, prueba descartando 1 o 2 √∫ltimas fechas de la serie vieja para ver si son outliers.

Si no mejora ‚Üí hay un step real en ambas series ‚Üí uni√≥n en la √∫ltima fecha de la serie vieja.

Acumulaci√≥n continua

Calcula los incrementos de la serie nueva.

Ajusta la nueva serie para que empiece desde el valor correspondiente de la serie vieja en el punto de uni√≥n.

Genera una acumulaci√≥n continua sin duplicar fechas.

Guardado

Copia datasets est√°ticos (no temporales) directamente.

Combina imdates, bperp y cum en el archivo de salida.

Detalles t√©cnicos clave

RMS autom√°tico:

Se calcula como 2œÉ de los incrementos en la zona de solapamiento, es decir, dos veces la desviaci√≥n est√°ndar de los cambios entre fechas consecutivas.

Esto hace que el script se adapte a series con distinta variabilidad, sin depender de un valor fijo de RMS.

Incrementos y acumulaci√≥n

La serie nueva se transforma en incrementos (Œîcum) para luego sumarlos al √∫ltimo valor de la serie vieja.

Esto garantiza que la serie combinada sea continuamente acumulada.

Manejo de steps

El script detecta pasos bruscos (‚Äústep‚Äù) en la serie vieja o en ambas.

Seg√∫n d√≥nde est√© el step, decide unir en la primera fecha de solapamiento o en la √∫ltima fecha de la serie vieja.

Mensajes que muestra al usuario

RMS en solapamiento = ... ‚Üí indica coherencia entre series.

√öltima fecha old parece outlier ‚Üí detecta si la serie vieja tiene valores at√≠picos.

Solapamiento incoherente o step en ambas series ‚Üí el script decide unir al final de la serie vieja.

Combined data saved to ... ‚Üí confirma que el archivo combinado se gener√≥ correctamente.

Resumen visual del proceso
Serie antigua:  |-----|-----|-----|-----|
Serie nueva:        |-----|-----|-----|
                    ‚Üë Uni√≥n ajustada por RMS
Acumulaci√≥n final: |-----|-----|-----|-----|-----|-----|-----|


Si hay un step solo en la serie vieja ‚Üí el script ajusta la uni√≥n para evitar el error.

Si el step est√° en ambas series ‚Üí la uni√≥n se hace al final de la serie vieja.

 En pocas palabras:
El script garantiza que las series de tiempo acumuladas se unan de forma suave y continua, detectando autom√°ticamente cambios bruscos y adaptando la uni√≥n seg√∫n la coherencia entre las series, usando un umbral RMS autom√°tico basado en la variabilidad de los incrementos.
'''
